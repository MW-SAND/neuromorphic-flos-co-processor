""" 
This script has been generated by AI with minor tweaks from the author

This script generates a cheader file with 
-> The input events
-> The weights and biases
-> The bitmap
-> The expected output

using the quantized VGG16 model
"""

# import keras
import numpy as np
import cv2
from tensorflow.keras.datasets import cifar10
from tensorflow.keras.layers import Layer
from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, LearningRateScheduler
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.utils import to_categorical
import matplotlib.pyplot as plt
from tensorflow.keras import optimizers
import tensorflow as tf


class ScalingLayer(Layer):
    def __init__(self, scale_factor, clipping_range, active, **kwargs):
        super(ScalingLayer, self).__init__(**kwargs)
        self.scale_factor = scale_factor
        self.clipping_range = clipping_range
        self.active = active

    def call(self, inputs, training=None):
        # Scale the inputs
        scaled = inputs * self.scale_factor

        if training:
            # During training, use straight-through estimator for rounding
            # Forward pass: use rounded values
            # Backward pass: gradients flow as if rounding wasn't there
            rounded = tf.round(scaled)
            rounded_straight_through = scaled + \
                tf.stop_gradient(rounded - scaled)

            # Apply clipping and return
            if self.active:
                return tf.clip_by_value(rounded_straight_through,
                                        self.clipping_range[0],
                                        self.clipping_range[1])
            else:
                return scaled
        else:
            # During inference, just apply rounding and clipping as before
            if self.active:
                return tf.clip_by_value(tf.round(scaled),
                                        self.clipping_range[0],
                                        self.clipping_range[1])
            else:
                return scaled

    def get_config(self):
        config = super(ScalingLayer, self).get_config()
        config.update({
            "scale_factor": self.scale_factor,
            "clipping_range": self.clipping_range
        })
        return config


def load_dataset():
    """
    Loads the CIFAR-10 dataset.
    """
    return cifar10.load_data()


def evaluate(model, class_count=10, image_height=32, image_width=32):
    """
    Evaluates the model on the CIFAR-10 test set.
    """
    (_, _), (x_test, y_test) = load_dataset()
    x_test = (x_test / 36).astype('int')  # Normalize data
    batch_size = 1
    steps = len(x_test) // batch_size
    test_gen = generator(batch_size, class_count,
                         image_height, image_width, x_test, y_test)

    # using evaluate generator; adjust verbosity as needed
    scores = model.evaluate(test_gen, steps=steps, verbose=0)
    print("Test Loss:\t", scores[0])
    print("Test Accuracy:\t", scores[1])


def quantizeWeights(parameters):
    """
    Loads a trained model, iterates over its layers (e.g., Conv2D and Dense layers),
    quantizes the kernel weights based on parameters (clipping_range, percentile, etc),
    retrains for 2 epochs after quantizing each layer, then requantizes the same layer.
    Finally, saves the model.

    Expected keys in parameters:
      - model_path:          path to the pretrained model (default "VGG16.model")
      - output_model_path:   where to save the quantized model (default "VGG16_qW.model")
      - clipping_range:      tuple (min, max) for clipping, e.g. (-7, 7)
      - percentile:          percentile value (e.g., 95)
      - evalLayer:           Boolean flag; if True, evaluate after each quantization step
      - class_count:         number of classes (e.g., 10 for CIFAR-10 evaluation)
      - image_height:        evaluation image height
      - image_width:         evaluation image width
    """
    # Extract parameters with defaults and load the model
    model_path = parameters.get("model_path", "VGG16_qA.model")
    output_model_path = parameters.get("output_model_path", "VGG16_qW.model")
    clipping_range_weights = parameters.get("clipping_range_weights", (-7, 7))
    clipping_range_bias = parameters.get("clipping_range_bias", (-7, 7))
    percentile = parameters.get("percentile", 95)
    evalLayer = parameters.get("evalLayer", False)
    class_count = parameters.get("class_count", 10)
    image_height = parameters.get("image_height", 32)
    image_width = parameters.get("image_width", 32)
    batch_size = parameters.get("batch_size", 1)

    print(f"Loading model from {model_path}")
    model = keras.models.load_model(model_path)

    # (Re)compile the model to ensure it can be trained
    model.compile(optimizer=optimizers.SGD(learning_rate=0.001, momentum=0.9),
                  loss='categorical_crossentropy', metrics=['accuracy'])

    # Load training dataset for the retraining step (CIFAR-10 here)
    (x_train, y_train), (x_test, y_test) = load_dataset()
    x_train, x_test = np.floor(
        x_train / 36).astype('float32'), np.floor(x_test / 36).astype('float32')  # Normalize data
    y_train = to_categorical(y_train, class_count)
    y_test = to_categorical(y_test, class_count)

    x_val = x_train[40000:]
    y_val = y_train[40000:]

    x_train = x_train[:40000]
    y_train = y_train[:40000]

    # Train model
    def lr_scheduler(epoch):
        return 0.001 * (0.5 ** (epoch // 20))
    reduce_lr = LearningRateScheduler(lr_scheduler)

    # construct the training image generator for data augmentation
    aug = ImageDataGenerator(
        rotation_range=20,
        zoom_range=0.15,
        width_shift_range=0.2,
        height_shift_range=0.2,
        shear_range=0.15,
        horizontal_flip=True,
        fill_mode="nearest")

    if evalLayer:
        print("   Evaluation before first quantization:")
        loss, accuracy = model.evaluate(x_test, y_test)
        print(f'Validation loss: {loss:.2f}\nTest Accuracy: {accuracy:.2f}')
        # plot_prediction_histograms(model, x_test, class_count)

    # Iterate over model layers; for each layer with weights, quantize then train and requantize.
    for idx, layer in enumerate(model.layers):
        if isinstance(layer, (tf.keras.layers.Conv2D, tf.keras.layers.Dense)):
            weights = layer.get_weights()
            if not weights:
                continue  # Skip layers with no weights

            print(f"\n--- Processing layer {idx}: {layer.name} ---")
            # ---- FIRST QUANTIZATION STEP ----
            kernel_weights = weights[0]
            # Compute the absolute values and determine the clipping threshold
            p_value = np.percentile(np.abs(kernel_weights), percentile)
            scaling_factor = p_value / \
                clipping_range_weights[1] if clipping_range_weights[1] != 0 else 1.0
            # Scale, round, and clip the weights
            weights_scaled = kernel_weights / scaling_factor
            weights_rounded = np.rint(weights_scaled)
            weights_quantized = np.clip(
                weights_rounded, clipping_range_weights[0], clipping_range_weights[1])
            print(
                f"   First quantization: {percentile}th percentile = {p_value:.4f}, scaling factor = {scaling_factor:.4f}")

            # Change bias
            bias = weights[1]
            bias_scaled = bias / scaling_factor
            bias_rounded = np.rint(bias_scaled)
            bias_quantized = np.clip(
                bias_rounded, clipping_range_bias[0], clipping_range_bias[1])

            new_weights = [weights_quantized, bias]
            layer.set_weights(new_weights)

            if layer.name != "predictions":
                new_scaling_factor = model.layers[idx +
                                                  1].scale_factor.numpy() * scaling_factor
                model.layers[idx+1].scale_factor.assign(new_scaling_factor)

    if evalLayer:
        print("   Evaluation after first quantization of this layer:")
        loss, accuracy = model.evaluate(x_test, y_test)
        print(f'Validation loss: {loss:.2f}\nTest Accuracy: {accuracy:.2f}')
        # plot_prediction_histograms(model, x_test, class_count)

    # Save the fully quantized model
    model.save(output_model_path)
    print(f"\nQuantized model saved as: {output_model_path}")


# Example call: modify parameters as needed
if __name__ == "__main__":
    parameters = {
        "model_path": "VGG16_qW.model",           # path to your trained model
        "output_model_path": "VGG16_qW.model",   # output quantized model filename
        # quantization clipping range
        "clipping_range_weights": (-7, 7),
        # quantization clipping range
        "clipping_range_bias": (-32767, 32767),
        "percentile": 95,                      # percentile for scaling factor determination
        # set to True to evaluate after each quantization step
        "evalLayer": True,
        "class_count": 10,                     # CIFAR-10 has 10 classes
        "image_height": 32,                    # evaluation image height
        "image_width": 32,                      # evaluation image width
        "batch_size": 128
    }

    quantizeWeights(parameters)
