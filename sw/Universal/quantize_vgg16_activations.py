""" 
The framework of this model (i.e. loading the model and dataset) has been generated by AI
The quantization method has been designed and implemented by the author

This script quantizes the activations of an existing VGG16 model and inserts scaling layers to perform the quantization 
"""

import tensorflow as tf
from tensorflow.keras.applications import VGG16
from tensorflow.keras.models import Model, Sequential
from tensorflow.keras.layers import Dense, Flatten, Dropout
from tensorflow.keras import optimizers
from tensorflow.keras.datasets import cifar10
from tensorflow.keras.utils import to_categorical
from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, LearningRateScheduler
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.utils import plot_model
import numpy as np
from tensorflow.keras import backend as K
from tensorflow.keras.layers import Layer
import cv2
import keras


class ScalingLayer(Layer):
    def __init__(self, scale_factor, clipping_range, active, **kwargs):
        super(ScalingLayer, self).__init__(**kwargs)
        self.scale_factor = self.add_weight(
            name="scale_factor",
            shape=(),
            initializer=tf.constant_initializer(scale_factor),
            trainable=False 
        )
        self.clipping_range = clipping_range
        self.active = active

    def call(self, inputs, training=None):
        # Scale the inputs
        scaled = inputs * self.scale_factor

        if training:
            # During training, use straight-through estimator for rounding
            # Forward pass: use rounded values
            # Backward pass: gradients flow as if rounding wasn't there
            rounded = tf.round(scaled)
            rounded_straight_through = scaled + \
                tf.stop_gradient(rounded - scaled)

            # Apply clipping and return
            if self.active:
                return tf.clip_by_value(rounded_straight_through,
                                        self.clipping_range[0],
                                        self.clipping_range[1])
            else:
                return scaled
        else:
            # During inference, just apply rounding and clipping as before
            if self.active:
                return tf.clip_by_value(tf.round(scaled),
                                        self.clipping_range[0],
                                        self.clipping_range[1])
            else:
                return scaled

    def get_config(self):
        config = super(ScalingLayer, self).get_config()
        config.update({
            "clipping_range": self.clipping_range
        })
        return config


def evaluate(model, class_count=10, image_height=32, image_width=32):
    """
    Evaluates the model on the CIFAR-10 test set.
    """
    (_, _), (x_test, y_test) = load_dataset()
    x_test = (x_test / 36).astype('int')  # Normalize data
    batch_size = 1
    steps = len(x_test) // batch_size
    test_gen = generator(batch_size, class_count,
                         image_height, image_width, x_test, y_test)

    # using evaluate generator; adjust verbosity as needed
    scores = model.evaluate(test_gen, steps=steps, verbose=0)
    print("Test Loss:\t", scores[0])
    print("Test Accuracy:\t", scores[1])


def load_dataset():
    """
    Loads the CIFAR-10 dataset.
    """
    return keras.datasets.cifar10.load_data()


def quantizeActivations(parameters):
    # Extract parameters (with defaults)
    model_path = parameters.get("model_path", "VGG16_qW.model")
    output_model_path = parameters.get("output_model_path", "VGG16_qA.model")
    clipping_range = parameters.get("clipping_range", (-7, 7))
    percentile = parameters.get("percentile", 95)
    evalLayer = parameters.get("evalLayer", False)
    class_count = parameters.get("class_count", 10)
    image_height = parameters.get("image_height", 32)
    image_width = parameters.get("image_width", 32)
    batch_size = parameters.get("batch_size", 1)

    # Load the model with quantized weights.
    print(f"Loading quantized weights model from {model_path}")
    model = keras.models.load_model(model_path)

    # Load test data (CIFAR-100) and resize each image.
    (x_train, y_train), (x_test, y_test) = load_dataset()
    x_train, x_test = np.floor(
        x_train / 36).astype('float32'), np.floor(x_test / 36).astype('float32')  # Normalize data
    y_train = to_categorical(y_train, class_count)
    y_test = to_categorical(y_test, class_count)

    x_val = x_train[40000:]
    y_val = y_train[40000:]

    x_train = x_train[:40000]
    y_train = y_train[:40000]

    def lr_scheduler(epoch):
        return 0.001 * (0.1 ** (epoch // 1))
    reduce_lr = LearningRateScheduler(lr_scheduler)

    # construct the training image generator for data augmentation
    aug = ImageDataGenerator(
        rotation_range=20,
        zoom_range=0.15,
        width_shift_range=0.2,
        height_shift_range=0.2,
        shear_range=0.15,
        horizontal_flip=True,
        fill_mode="nearest")

    idx = 0

    # Add scaling layers, with default scaling factor
    quant_model = Sequential()
    for layer in model.layers:
        quant_model.add(layer)

        if isinstance(layer, (tf.keras.layers.Conv2D, tf.keras.layers.Dense)):
            if layer.name != "predictions":
                quant_model.add(ScalingLayer(1, clipping_range, False))

    # Compile the model and evaluate
    quant_model.compile(optimizer=optimizers.SGD(
        learning_rate=0.0001, momentum=0.7), loss='categorical_crossentropy', metrics=['accuracy'])
    if evalLayer:
        print("   Evaluation before activation quantization:")
        loss, accuracy = quant_model.evaluate(x_test, y_test)
        print(f'Validation loss: {loss:.2f}\nTest Accuracy: {accuracy:.2f}')
    quant_model.summary()
    quant_model.save(output_model_path)

    # Loop over all layres
    for idx, layer in enumerate(quant_model.layers):
        if isinstance(layer, ScalingLayer):
            print(
                f"Processing activation of layer {idx} ({layer.name}), output shape: {layer.output_shape}")
            # Build an intermediate model to capture the output from the current layer.
            intermediate_model = tf.keras.models.Model(
                inputs=quant_model.input, outputs=layer.output)
            sample_size = min(100, x_test.shape[0])
            sample_x = x_test[:sample_size]
            
            # Compute the activation outputs.
            act = intermediate_model.predict(sample_x, batch_size=batch_size)
            
            # Compute the chosen percentile of the absolute activation values.
            p_value = np.percentile(np.abs(act), percentile)
            print(f"   {percentile}th percentile of activations: {p_value}")

            if p_value == 0:
                scaling_factor = 1.0
                print("   Warning: Percentile value is 0; setting scaling factor to 1.0")
            else:
                scaling_factor = clipping_range[1] / p_value
            print(
                f"   Inserting ScalingLayer with scale factor: {scaling_factor}")

            # Assign the scale factor
            layer.scale_factor.assign(scaling_factor)
            layer.trainable = True
            layer.active = True
            quant_model.layers[idx-1].trainable = True

            # Compile and evaluate
            quant_model.compile(optimizer=optimizers.SGD(
                learning_rate=0.0001, momentum=0.7), loss='categorical_crossentropy', metrics=['accuracy'])
            if evalLayer:
                print("   Evaluation after activation quantization:")
                loss, accuracy = quant_model.evaluate(x_test, y_test)
                print(
                    f'Validation loss: {loss:.2f}\nTest Accuracy: {accuracy:.2f}')

            # Retrain the model
            if accuracy < 0.85:
                print(
                    f"   Retraining entire model for 1 epochs after scaling layer {layer.name}...")
                history = quant_model.fit(aug.flow(x_train, y_train, batch_size=batch_size), validation_data=(
                    x_val, y_val), steps_per_epoch=len(x_train) // batch_size, epochs=2, callbacks=[reduce_lr])

                # Optionally evaluate the intermediate model right now.
                if evalLayer:
                    print("   Evaluation after activation quantization:")
                    loss, accuracy = quant_model.evaluate(x_test, y_test)
                    print(
                        f'Validation loss: {loss:.2f}\nTest Accuracy: {accuracy:.2f}')

            print()
            print()
            print()
            print()

    # Build, compile, and evaluate the final network.
    loss, acc = quant_model.evaluate(
        x_test, y_test, batch_size=batch_size, verbose=0)
    quant_model.summary()
    print(
        "\nFinal Quantized Activation Model Test Accuracy: {:.1f}%".format(acc*100))

    # Save the model with quantized activations.
    quant_model.save(output_model_path)
    print(f"Quantized activation model saved as: {output_model_path}")

    for layer in quant_model.layers:
        if isinstance(layer, ScalingLayer):
            print(
                f"layer_name: {layer.name}, scale_factor: {layer.scale_factor}")


# Example of calling the function:
if __name__ == "__main__":
    parameters = {
        "model_path": "VGG16_mc_SGD_D55.model",
        "output_model_path": "VGG16_qA.model",   # output quantized model filename
        "clipping_range": (-7, 7),             # quantization clipping range
        # percentile for scaling factor determination
        "percentile": 95,
        "evalLayer": True,                         # evaluate after each layer is quantized
        "class_count": 10,                        # use 10 classes for CIFAR-10 evaluation
        "image_height": 32,                       # evaluation image height
        "image_width": 32,                         # evaluation image width
        "batch_size": 128
    }

    quantizeActivations(parameters)
